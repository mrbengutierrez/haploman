
<!DOCTYPE html>
<html>
<head>
	<title class="project-name"></title>

	<!-- Shared Head -->
	<script type="text/javascript" src="../../shared-resources/shared-head.js"></script>

	<!-- Project Styling -->
	<link rel="stylesheet" type="text/css" href="../projects-styles.css">


	
</head>
<body>

	<!--  Navigation Bar -->
	<script type="text/javascript" src="../../shared-resources/shared-navigation.js"></script>

	<div class="section section-yin">
		<h1 class="extra-large-heading top-heading project-name"></h1>
	</div>


	<div class="section section-yang content-align-rule">

		<h2 class="increment-2-heading project-date"></h2>

		<h2 class="increment-3-heading">Brief Description</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			This collaborative manipulator was made as part of a team project for the 2.12 Collaborative Robotics Competition. The core idea behind the competition was to develop a manipulator for hemiplegic patients. Hemiplegia is a condition caused by brain damage or spinal cord injury that leads to paralysis on one side of the body. The tasks that the manipulator needed to assist with were drawer opening and garment donning. As part of the competition, our project budget was limited to $500 or less.
		</p> 

		<h2 class="increment-3-heading">Serial Elastic Actuator (SEA)</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			The SEA was used to help determine what the applied force was on the end effector. Our SEA used two aluminum flexures in series as an elastic element. It had a rigid structure with fully supported shafts. We operated the SEA with state space control and utilized communication via Robot Operating System (ROS). In order to account for gear backlash, we used initial arm movements as a calibration step. This allowed for more accurate force sensing
		</p> 

		<h2 class="increment-3-heading">Kinect Camera</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			We used a kinect camera to help the robot recognize where its target was. For the drawer opening task, there was an AprilTag on the front of the drawer that the kinect camera could use. We chose to use a kinect camera because it was able to provide red-green-blue (RGB) images at a reasonable frame rate. We utilized a RGB-Depth pixel map and transformed into real world coordinates. We used machine vision to recognize and localize on obstacles and targets.
		</p> 

		<h2 class="increment-3-heading">Inertial Measurement Unit (IMU)</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			An IMU was used for remote control operation of the manipulator. The idea was that the hemiplegic patient could tilt a lightweight remote control with their disabled arm to control the arm. They could use their functional arm to do tasks while using their disabled arm to control their assistive robot. We chose to use an IMU for our remote control because it can measure three-axis acceleration in pitch, yaw, and roll. This pitch, yaw, and roll was translated to XYZ velocity commands. We also had a button on the remote that would enable or disable tracking.
		</p> 

		<h2 class="increment-3-heading">Drawer Opening</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			For the drawer opening task, we had to assist a hemiplegic patient with opening a drawer. The hemiplegic patient would use their functional arm to grab one end of the drawer and the manipulator would grab the other end of the drawer. The challenges in this task were localization of the drawer's handle, gripping the handle, and human-robot coordination.
		</p>

		<p>
			To accomplish this task we made our own wearable motion controller. An IMU on the remote control would track human intention. The user could press a button on the remote to activate grasp or imitation initiation. The remote control communicated wirelessly via bluetooth with the manipulator computer. Hence, the position control of the manipulator arm was IMU-controlled.
		</p>

		<p>
		One of our concerns during the competition was patient safety. The SEA that we designed had passive safety because of the springyness of the elastic element meant that the end effector had a finite stiffness. This would help to passively reduce the impact of a collisition with a user.</p>



		<h2 class="increment-3-heading">Garment Donning</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<p>
			For the garment donning task, we had to assist a hemiplegic patient with wrapping a towel. The key challenges were trajectory planning, avoiding the patient, and developing position and velocity control.
		</p>

		<p>
			The way we implemented the software in the competition was by hard coding path information in Matlab and converting the code into python and ROS. We simulated a path to avoid collisions with an average-sized patient. We used velocity control and waypoints to develop the path. The position control was derived from forward kinematics.
		</p>



		<h2 class="increment-3-heading">Team</h2>
		<hr class="medium-divider">
		<div id=extra-space></div>

		<div>
			<p><strong>Sensors</strong></p>
			<p>Joe Huang, Xiaotong Zhang</p>

			<p><strong>Serial Elastic Actuator</strong></p>
			<p>Krithika Swami, Taylor V'Dovec, Jason Fischman</p>

			<p><strong>Manipulator</strong></p>
			<p>Benjamin Gutierrez, Jasmin Palmer</p>
		</div>




		<div class="center">

			<div id=extra-space></div>

			<a href="https://drive.google.com/uc?export=view&id=1fGhUD5pPMYitJhl6rECK9bbNy-eeFbcE"><img class="responsive-feature-image" src="https://drive.google.com/uc?export=view&id=1fGhUD5pPMYitJhl6rECK9bbNy-eeFbcE" class="responsive-feature-image" title="Click for the larger version." /></a>

			<div id=extra-space></div>

			<a href="https://drive.google.com/uc?export=view&id=1X8UbhIzDb11hjEuRu0w8QarK-SWLL10Q"><img class="responsive-feature-image" src="https://drive.google.com/uc?export=view&id=1X8UbhIzDb11hjEuRu0w8QarK-SWLL10Q" class="responsive-feature-image" title="Click for the larger version." /></a>

			<div id=extra-space></div>

		</div>


		<h2 class="increment-3-heading">Competition (Audio Not Available)</h2>

		<hr class="medium-divider">
		<div id=extra-space></div>

		<div class="center embed-responsive embed-responsive-16by9">
			<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/--vgBtn6s64" allowfullscreen></iframe>
		</div>

		<h2 class="increment-3-heading">Testing the Robot</h2>

		<hr class="medium-divider">
		<div id=extra-space></div>


		<div class="center embed-responsive embed-responsive-16by9">
			<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/wvQuXjFohh0" allowfullscreen></iframe>
		</div>

		<div id=extra-space></div>


		<div class="center embed-responsive embed-responsive-16by9">
			<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/PG84zyqVcIA" allowfullscreen></iframe>
		</div>

		<div id=extra-space></div>


		<div class="center embed-responsive embed-responsive-16by9">
			<iframe class="embed-responsive-item" src="https://www.youtube.com/embed/0fkOA0MyBLI" allowfullscreen></iframe>
		</div>


	</div>



	<!-- Shared Footer -->
	<script type="text/javascript" src="../../shared-resources/shared-footer.js"></script>
	<script type="text/javascript" src="../projects-data.json"></script>
	<script type="text/javascript" src="../projects-script.js"></script>
</body>
</html>

